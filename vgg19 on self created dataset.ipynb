{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense,Activation,Flatten,ZeroPadding2D,Conv2D,BatchNormalization\n",
    "from keras.layers import AveragePooling2D,MaxPooling2D,GlobalAveragePooling2D,GlobalMaxPooling2D,Dropout\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import layer_utils\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1=\"C:\\dataset 2\"\n",
    "path2=\"C:\\dataset 2 after preprocessing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing=os.listdir(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path3=\"C:\\dataset 2 after preprocessing vgg19\"\n",
    "for file in listing:\n",
    "    im=Image.open(path1 +'\\\\'+ file)\n",
    "    im=im.resize((224,224))\n",
    "    im.save(path3 + '\\\\'+ file,\"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list3=os.listdir(path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "immatrix_new=np.array([np.array(Image.open('C:\\dataset 2 after preprocessing vgg19' + '\\\\'+ i)).flatten() for i in list3],'f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=np.ones((immatrix_new.shape[0],),dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[0:14]=0\n",
    "label[14:25]=1\n",
    "label[25:36]=2\n",
    "label[36:49]=3\n",
    "label[49:]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,l=shuffle(immatrix_new,label,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[d,l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25485035198>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=immatrix_new[1].reshape(224,224,3)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 150528) (56,)\n"
     ]
    }
   ],
   "source": [
    "print(train[0].shape,train[1].shape)\n",
    "X,Y=(train[0],train[1])\n",
    "train_x,test_x,train_y,test_y=train_test_split(X,Y,test_size=0.4,random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x.reshape(train_x.shape[0],224,224,3)\n",
    "test_x=test_x.reshape(test_x.shape[0],224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.astype('float32')\n",
    "test_x.astype('float32')\n",
    "train_x/=255\n",
    "test_x/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=np_utils.to_categorical(train_y,5)\n",
    "test_y=np_utils.to_categorical(test_y,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 5)\n",
      "(23, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vgg19 net\n",
    "model=Sequential()\n",
    "\n",
    "#Block1\n",
    "model.add(Conv2D(64,(3,3),strides=(1,1),padding=\"same\",input_shape=(224,224,3)))\n",
    "convout1=Activation('relu')\n",
    "model.add(convout1)\n",
    "model.add(Conv2D(64,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout2=Activation('relu')\n",
    "model.add(convout2)\n",
    "model.add(MaxPooling2D((2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "#Block2\n",
    "model.add(Conv2D(128,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout3=Activation('relu')\n",
    "model.add(convout3)\n",
    "model.add(Conv2D(128,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout4=Activation('relu')\n",
    "model.add(convout4)\n",
    "model.add(MaxPooling2D((2,2),strides=(2,2)))\n",
    "\n",
    "#Block3\n",
    "model.add(Conv2D(256,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout5=Activation('relu')\n",
    "model.add(convout5)\n",
    "model.add(Conv2D(256,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout6=Activation('relu')\n",
    "model.add(convout6)\n",
    "model.add(Conv2D(256,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout7=Activation('relu')\n",
    "model.add(convout7)\n",
    "model.add(Conv2D(256,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout8=Activation('relu')\n",
    "model.add(convout8)\n",
    "model.add(MaxPooling2D((2,2),strides=(2,2)))\n",
    "\n",
    "\n",
    "#Block4\n",
    "model.add(Conv2D(512,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout9=Activation('relu')\n",
    "model.add(convout9)\n",
    "model.add(Conv2D(512,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout10=Activation('relu')\n",
    "model.add(convout10)\n",
    "model.add(Conv2D(512,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout11=Activation('relu')\n",
    "model.add(convout11)\n",
    "model.add(Conv2D(512,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout12=Activation('relu')\n",
    "model.add(convout12)\n",
    "model.add(MaxPooling2D((2,2),strides=(2,2)))\n",
    "\n",
    "#Block5\n",
    "model.add(Conv2D(512,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout13=Activation('relu')\n",
    "model.add(convout13)\n",
    "model.add(Conv2D(512,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout14=Activation('relu')\n",
    "model.add(convout14)\n",
    "model.add(Conv2D(512,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout15=Activation('relu')\n",
    "model.add(convout15)\n",
    "model.add(Conv2D(512,(3,3),strides=(1,1),padding=\"same\"))\n",
    "convout16=Activation('relu')\n",
    "model.add(convout16)\n",
    "model.add(MaxPooling2D((2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adadelta',loss='categorical_crossentropy',metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "33/33 [==============================] - 91s 3s/step - loss: 1.6086 - acc: 0.2727 - val_loss: 1.6069 - val_acc: 0.2609\n",
      "Epoch 2/100\n",
      "33/33 [==============================] - 9157s 277s/step - loss: 1.6160 - acc: 0.2424 - val_loss: 1.6086 - val_acc: 0.1739\n",
      "Epoch 3/100\n",
      "33/33 [==============================] - 92s 3s/step - loss: 1.6284 - acc: 0.2727 - val_loss: 1.6064 - val_acc: 0.2609\n",
      "Epoch 4/100\n",
      "33/33 [==============================] - 96s 3s/step - loss: 1.5981 - acc: 0.2424 - val_loss: 1.6083 - val_acc: 0.1739\n",
      "Epoch 5/100\n",
      "33/33 [==============================] - 93s 3s/step - loss: 1.5962 - acc: 0.2727 - val_loss: 1.6096 - val_acc: 0.1739\n",
      "Epoch 6/100\n",
      "33/33 [==============================] - 87s 3s/step - loss: 1.5950 - acc: 0.2727 - val_loss: 1.6105 - val_acc: 0.1739\n",
      "Epoch 7/100\n",
      "33/33 [==============================] - 83s 3s/step - loss: 1.5896 - acc: 0.1818 - val_loss: 1.6142 - val_acc: 0.1739\n",
      "Epoch 8/100\n",
      "33/33 [==============================] - 83s 3s/step - loss: 1.5927 - acc: 0.2727 - val_loss: 1.6132 - val_acc: 0.1739\n",
      "Epoch 9/100\n",
      "33/33 [==============================] - 90s 3s/step - loss: 1.5888 - acc: 0.2727 - val_loss: 1.6153 - val_acc: 0.1739\n",
      "Epoch 10/100\n",
      "33/33 [==============================] - 85s 3s/step - loss: 1.5864 - acc: 0.2727 - val_loss: 1.6185 - val_acc: 0.1739\n",
      "Epoch 11/100\n",
      "33/33 [==============================] - 82s 2s/step - loss: 1.5861 - acc: 0.2727 - val_loss: 1.6190 - val_acc: 0.1739\n",
      "Epoch 12/100\n",
      "33/33 [==============================] - 85s 3s/step - loss: 1.5863 - acc: 0.2727 - val_loss: 1.6192 - val_acc: 0.1739\n",
      "Epoch 13/100\n",
      "33/33 [==============================] - 88s 3s/step - loss: 1.5916 - acc: 0.2727 - val_loss: 1.6184 - val_acc: 0.1739\n",
      "Epoch 14/100\n",
      "33/33 [==============================] - 94s 3s/step - loss: 1.5878 - acc: 0.2727 - val_loss: 1.6194 - val_acc: 0.1739\n",
      "Epoch 15/100\n",
      "33/33 [==============================] - 89s 3s/step - loss: 1.5920 - acc: 0.1515 - val_loss: 1.6202 - val_acc: 0.1739\n",
      "Epoch 16/100\n",
      "33/33 [==============================] - 86s 3s/step - loss: 1.5913 - acc: 0.2727 - val_loss: 1.6183 - val_acc: 0.1739\n",
      "Epoch 17/100\n",
      "33/33 [==============================] - 81s 2s/step - loss: 1.5849 - acc: 0.2727 - val_loss: 1.6192 - val_acc: 0.1739\n",
      "Epoch 18/100\n",
      "33/33 [==============================] - 80s 2s/step - loss: 1.5880 - acc: 0.2727 - val_loss: 1.6192 - val_acc: 0.1739\n",
      "Epoch 19/100\n",
      "33/33 [==============================] - 80s 2s/step - loss: 1.5884 - acc: 0.2727 - val_loss: 1.6181 - val_acc: 0.1739\n",
      "Epoch 20/100\n",
      "33/33 [==============================] - 82s 2s/step - loss: 1.5834 - acc: 0.2727 - val_loss: 1.6203 - val_acc: 0.1739\n",
      "Epoch 21/100\n",
      "33/33 [==============================] - 80s 2s/step - loss: 1.5956 - acc: 0.2727 - val_loss: 1.6204 - val_acc: 0.1739\n",
      "Epoch 22/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5956 - acc: 0.2727 - val_loss: 1.6180 - val_acc: 0.1739\n",
      "Epoch 23/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5895 - acc: 0.2727 - val_loss: 1.6195 - val_acc: 0.1739\n",
      "Epoch 24/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5948 - acc: 0.2727 - val_loss: 1.6178 - val_acc: 0.1739\n",
      "Epoch 25/100\n",
      "33/33 [==============================] - 85s 3s/step - loss: 1.5872 - acc: 0.2727 - val_loss: 1.6175 - val_acc: 0.1739\n",
      "Epoch 26/100\n",
      "33/33 [==============================] - 88s 3s/step - loss: 1.5847 - acc: 0.2727 - val_loss: 1.6193 - val_acc: 0.1739\n",
      "Epoch 27/100\n",
      "33/33 [==============================] - 87s 3s/step - loss: 1.5842 - acc: 0.2727 - val_loss: 1.6198 - val_acc: 0.1739\n",
      "Epoch 28/100\n",
      "33/33 [==============================] - 94s 3s/step - loss: 1.5844 - acc: 0.2727 - val_loss: 1.6205 - val_acc: 0.1739\n",
      "Epoch 29/100\n",
      "33/33 [==============================] - 96s 3s/step - loss: 1.5875 - acc: 0.2727 - val_loss: 1.6212 - val_acc: 0.1739\n",
      "Epoch 30/100\n",
      "33/33 [==============================] - 95s 3s/step - loss: 1.5826 - acc: 0.2727 - val_loss: 1.6222 - val_acc: 0.1739\n",
      "Epoch 31/100\n",
      "33/33 [==============================] - 94s 3s/step - loss: 1.5886 - acc: 0.2727 - val_loss: 1.6238 - val_acc: 0.1739\n",
      "Epoch 32/100\n",
      "33/33 [==============================] - 93s 3s/step - loss: 1.5858 - acc: 0.2727 - val_loss: 1.6231 - val_acc: 0.1739\n",
      "Epoch 33/100\n",
      "33/33 [==============================] - 94s 3s/step - loss: 1.5821 - acc: 0.2727 - val_loss: 1.6233 - val_acc: 0.1739\n",
      "Epoch 34/100\n",
      "33/33 [==============================] - 81s 2s/step - loss: 1.5875 - acc: 0.2727 - val_loss: 1.6229 - val_acc: 0.1739\n",
      "Epoch 35/100\n",
      "33/33 [==============================] - 85s 3s/step - loss: 1.5931 - acc: 0.2727 - val_loss: 1.6244 - val_acc: 0.1739\n",
      "Epoch 36/100\n",
      "33/33 [==============================] - 88s 3s/step - loss: 1.5872 - acc: 0.2727 - val_loss: 1.6236 - val_acc: 0.1739\n",
      "Epoch 37/100\n",
      "33/33 [==============================] - 83s 3s/step - loss: 1.5913 - acc: 0.2727 - val_loss: 1.6216 - val_acc: 0.1739\n",
      "Epoch 38/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5868 - acc: 0.2727 - val_loss: 1.6205 - val_acc: 0.1739\n",
      "Epoch 39/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5857 - acc: 0.2727 - val_loss: 1.6206 - val_acc: 0.1739\n",
      "Epoch 40/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5921 - acc: 0.2727 - val_loss: 1.6188 - val_acc: 0.1739\n",
      "Epoch 41/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5962 - acc: 0.2727 - val_loss: 1.6193 - val_acc: 0.1739\n",
      "Epoch 42/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5854 - acc: 0.2727 - val_loss: 1.6193 - val_acc: 0.1739\n",
      "Epoch 43/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5875 - acc: 0.2727 - val_loss: 1.6181 - val_acc: 0.1739\n",
      "Epoch 44/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5826 - acc: 0.2727 - val_loss: 1.6186 - val_acc: 0.1739\n",
      "Epoch 45/100\n",
      "33/33 [==============================] - 80s 2s/step - loss: 1.5854 - acc: 0.2727 - val_loss: 1.6206 - val_acc: 0.1739\n",
      "Epoch 46/100\n",
      "33/33 [==============================] - 83s 3s/step - loss: 1.5859 - acc: 0.2727 - val_loss: 1.6201 - val_acc: 0.1739\n",
      "Epoch 47/100\n",
      "33/33 [==============================] - 87s 3s/step - loss: 1.5895 - acc: 0.2727 - val_loss: 1.6207 - val_acc: 0.1739\n",
      "Epoch 48/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5898 - acc: 0.2727 - val_loss: 1.6212 - val_acc: 0.1739\n",
      "Epoch 49/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5863 - acc: 0.2727 - val_loss: 1.6215 - val_acc: 0.1739\n",
      "Epoch 50/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5870 - acc: 0.2727 - val_loss: 1.6211 - val_acc: 0.1739\n",
      "Epoch 51/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5991 - acc: 0.2727 - val_loss: 1.6207 - val_acc: 0.1739\n",
      "Epoch 52/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5905 - acc: 0.2727 - val_loss: 1.6208 - val_acc: 0.1739\n",
      "Epoch 53/100\n",
      "33/33 [==============================] - 80s 2s/step - loss: 1.5816 - acc: 0.2727 - val_loss: 1.6215 - val_acc: 0.1739\n",
      "Epoch 54/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5900 - acc: 0.2727 - val_loss: 1.6216 - val_acc: 0.1739\n",
      "Epoch 55/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5842 - acc: 0.2727 - val_loss: 1.6203 - val_acc: 0.1739\n",
      "Epoch 56/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5847 - acc: 0.2727 - val_loss: 1.6199 - val_acc: 0.1739\n",
      "Epoch 57/100\n",
      "33/33 [==============================] - 80s 2s/step - loss: 1.5896 - acc: 0.2727 - val_loss: 1.6200 - val_acc: 0.1739\n",
      "Epoch 58/100\n",
      "33/33 [==============================] - 84s 3s/step - loss: 1.5840 - acc: 0.2727 - val_loss: 1.6192 - val_acc: 0.1739\n",
      "Epoch 59/100\n",
      "33/33 [==============================] - 82s 2s/step - loss: 1.5915 - acc: 0.2727 - val_loss: 1.6209 - val_acc: 0.1739\n",
      "Epoch 60/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5855 - acc: 0.2727 - val_loss: 1.6216 - val_acc: 0.1739\n",
      "Epoch 61/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5840 - acc: 0.2727 - val_loss: 1.6220 - val_acc: 0.1739\n",
      "Epoch 62/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5848 - acc: 0.2727 - val_loss: 1.6227 - val_acc: 0.1739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5884 - acc: 0.2727 - val_loss: 1.6200 - val_acc: 0.1739\n",
      "Epoch 64/100\n",
      "33/33 [==============================] - 80s 2s/step - loss: 1.5863 - acc: 0.2727 - val_loss: 1.6211 - val_acc: 0.1739\n",
      "Epoch 65/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5876 - acc: 0.2727 - val_loss: 1.6199 - val_acc: 0.1739\n",
      "Epoch 66/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5868 - acc: 0.2727 - val_loss: 1.6175 - val_acc: 0.1739\n",
      "Epoch 67/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5969 - acc: 0.2727 - val_loss: 1.6196 - val_acc: 0.1739\n",
      "Epoch 68/100\n",
      "33/33 [==============================] - 79s 2s/step - loss: 1.5907 - acc: 0.2727 - val_loss: 1.6188 - val_acc: 0.1739\n",
      "Epoch 69/100\n",
      "33/33 [==============================] - 80s 2s/step - loss: 1.5839 - acc: 0.2727 - val_loss: 1.6197 - val_acc: 0.1739\n",
      "Epoch 70/100\n",
      "33/33 [==============================] - 87s 3s/step - loss: 1.5912 - acc: 0.2727 - val_loss: 1.6179 - val_acc: 0.1739\n",
      "Epoch 71/100\n",
      "33/33 [==============================] - 90s 3s/step - loss: 1.5827 - acc: 0.2727 - val_loss: 1.6190 - val_acc: 0.1739\n",
      "Epoch 72/100\n",
      "33/33 [==============================] - 88s 3s/step - loss: 1.5855 - acc: 0.2727 - val_loss: 1.6202 - val_acc: 0.1739\n",
      "Epoch 73/100\n",
      "33/33 [==============================] - 81s 2s/step - loss: 1.5874 - acc: 0.2727 - val_loss: 1.6199 - val_acc: 0.1739\n",
      "Epoch 74/100\n",
      "33/33 [==============================] - 88s 3s/step - loss: 1.5850 - acc: 0.2727 - val_loss: 1.6189 - val_acc: 0.1739\n",
      "Epoch 75/100\n",
      "33/33 [==============================] - 90s 3s/step - loss: 1.5842 - acc: 0.2727 - val_loss: 1.6192 - val_acc: 0.1739\n",
      "Epoch 76/100\n",
      "33/33 [==============================] - 90s 3s/step - loss: 1.5872 - acc: 0.2727 - val_loss: 1.6199 - val_acc: 0.1739\n",
      "Epoch 77/100\n",
      "33/33 [==============================] - 92s 3s/step - loss: 1.5875 - acc: 0.2727 - val_loss: 1.6202 - val_acc: 0.1739\n",
      "Epoch 78/100\n",
      "33/33 [==============================] - 89s 3s/step - loss: 1.5834 - acc: 0.2727 - val_loss: 1.6211 - val_acc: 0.1739\n",
      "Epoch 79/100\n",
      "33/33 [==============================] - 88s 3s/step - loss: 1.5893 - acc: 0.2727 - val_loss: 1.6211 - val_acc: 0.1739\n",
      "Epoch 80/100\n",
      "33/33 [==============================] - 89s 3s/step - loss: 1.5939 - acc: 0.2727 - val_loss: 1.6184 - val_acc: 0.1739\n",
      "Epoch 81/100\n",
      "33/33 [==============================] - 87s 3s/step - loss: 1.5915 - acc: 0.2727 - val_loss: 1.6174 - val_acc: 0.1739\n",
      "Epoch 82/100\n",
      "33/33 [==============================] - 90s 3s/step - loss: 1.5868 - acc: 0.2727 - val_loss: 1.6182 - val_acc: 0.1739\n",
      "Epoch 83/100\n",
      "33/33 [==============================] - 89s 3s/step - loss: 1.5864 - acc: 0.2727 - val_loss: 1.6191 - val_acc: 0.1739\n",
      "Epoch 84/100\n",
      "33/33 [==============================] - 85s 3s/step - loss: 1.5852 - acc: 0.2727 - val_loss: 1.6197 - val_acc: 0.1739\n",
      "Epoch 85/100\n",
      "33/33 [==============================] - 83s 3s/step - loss: 1.5902 - acc: 0.2727 - val_loss: 1.6191 - val_acc: 0.1739\n",
      "Epoch 86/100\n",
      "33/33 [==============================] - 89s 3s/step - loss: 1.5833 - acc: 0.2727 - val_loss: 1.6198 - val_acc: 0.1739\n",
      "Epoch 87/100\n",
      "33/33 [==============================] - 84s 3s/step - loss: 1.5819 - acc: 0.2727 - val_loss: 1.6195 - val_acc: 0.1739\n",
      "Epoch 88/100\n",
      "33/33 [==============================] - 88s 3s/step - loss: 1.5889 - acc: 0.2727 - val_loss: 1.6189 - val_acc: 0.1739\n",
      "Epoch 89/100\n",
      "33/33 [==============================] - 86s 3s/step - loss: 1.5848 - acc: 0.2727 - val_loss: 1.6188 - val_acc: 0.1739\n",
      "Epoch 90/100\n",
      "33/33 [==============================] - 86s 3s/step - loss: 1.5905 - acc: 0.2727 - val_loss: 1.6177 - val_acc: 0.1739\n",
      "Epoch 91/100\n",
      "33/33 [==============================] - 86s 3s/step - loss: 1.5857 - acc: 0.2727 - val_loss: 1.6182 - val_acc: 0.1739\n",
      "Epoch 92/100\n",
      "33/33 [==============================] - 86s 3s/step - loss: 1.5865 - acc: 0.2727 - val_loss: 1.6178 - val_acc: 0.1739\n",
      "Epoch 93/100\n",
      "33/33 [==============================] - 84s 3s/step - loss: 1.5838 - acc: 0.2727 - val_loss: 1.6184 - val_acc: 0.1739\n",
      "Epoch 94/100\n",
      "33/33 [==============================] - 85s 3s/step - loss: 1.5840 - acc: 0.2727 - val_loss: 1.6191 - val_acc: 0.1739\n",
      "Epoch 95/100\n",
      "33/33 [==============================] - 89s 3s/step - loss: 1.5834 - acc: 0.2727 - val_loss: 1.6192 - val_acc: 0.1739\n",
      "Epoch 96/100\n",
      "33/33 [==============================] - 82s 2s/step - loss: 1.5863 - acc: 0.2727 - val_loss: 1.6196 - val_acc: 0.1739\n",
      "Epoch 97/100\n",
      "33/33 [==============================] - 81s 2s/step - loss: 1.5813 - acc: 0.2727 - val_loss: 1.6200 - val_acc: 0.1739\n",
      "Epoch 98/100\n",
      "33/33 [==============================] - 92s 3s/step - loss: 1.5853 - acc: 0.2727 - val_loss: 1.6204 - val_acc: 0.1739\n",
      "Epoch 99/100\n",
      "33/33 [==============================] - 85s 3s/step - loss: 1.5835 - acc: 0.2727 - val_loss: 1.6209 - val_acc: 0.1739\n",
      "Epoch 100/100\n",
      "33/33 [==============================] - 83s 3s/step - loss: 1.5879 - acc: 0.2727 - val_loss: 1.6219 - val_acc: 0.1739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25485085860>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y,epochs=100,batch_size=11,validation_data=(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 15s 642ms/step\n",
      "test score 1.62190592289\n",
      "test accuracy 0.173913046718\n",
      "[3 3 3 3]\n",
      "[[ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(test_x,test_y)\n",
    "print(\"test score\",score[0])\n",
    "print(\"test accuracy\",score[1])\n",
    "print(model.predict_classes(test_x[1:5]))\n",
    "print(test_y[1:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 224, 224, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 112, 112, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 28, 28, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 20485     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 139,590,725\n",
      "Trainable params: 139,590,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
