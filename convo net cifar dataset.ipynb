{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classes=pd.read_csv(\"trainLabels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "#num_train, img_channels, img_rows, img_cols =  train_features.shape\n",
    "#num_test, _, _, _ =  test_features.shape\n",
    "#num_classes = len(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19],\n",
       "       [29],\n",
       "       [ 0],\n",
       "       ..., \n",
       "       [ 3],\n",
       "       [ 7],\n",
       "       [73]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x192e74605c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 10\n",
    "plt.imshow(X_train[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255.\n",
    "X_test = X_test/255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TensorFlow requires that you create placeholders for the input data that will be fed into the model when running the session.\n",
    "def create_placeholder(n_h,n_w,n_c,label):\n",
    "    \n",
    "    X=tf.placeholder(tf.float32,shape=(None,n_h,n_w,n_c))\n",
    "    Y=tf.placeholder(tf.float32,shape=(None,label))\n",
    "    \n",
    "    return X,Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(?, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholder(32, 32, 3, 100)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weight():\n",
    "    #    Initializes weight parameters to build a neural network with tensorflow.\n",
    "    tf.set_random_seed(1)\n",
    "    \n",
    "    w1=tf.get_variable(\"w1\",[5,5,3,20],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    w2=tf.get_variable(\"w2\",[5,5,20,20],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    w3=tf.get_variable(\"w3\",[5,5,20,20],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    w4=tf.get_variable(\"w4\",[5,5,20,20],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    w5=tf.get_variable(\"w5\",[5,5,20,20],initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "\n",
    "\n",
    "\n",
    "    parameters={\"w1\":w1,\n",
    "                \"w2\":w2, \n",
    "                \"w3\":w3,\n",
    "                \"w4\":w4,\n",
    "                 \"w5\":w5}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 = [-0.09227955  0.01970217 -0.01005384 -0.09455211 -0.07511778 -0.02913931\n",
      " -0.0081874  -0.05044512 -0.10122246 -0.02417627 -0.09030078 -0.04440387\n",
      "  0.02245919 -0.09806493  0.04956377  0.02185374  0.07320614  0.042335\n",
      "  0.06336805 -0.10107009]\n",
      "w2 = [ 0.00076752  0.07216509 -0.04682332  0.07209965  0.0732206  -0.02780577\n",
      " -0.03912907  0.0036763   0.07563546 -0.02299793 -0.01903649 -0.05896062\n",
      "  0.06914204  0.03984906 -0.0356699   0.07500588  0.02960422 -0.06865672\n",
      " -0.06381108 -0.05951216]\n",
      "w3 = [ 0.00076752  0.07216509 -0.04682332  0.07209965  0.0732206  -0.02780577\n",
      " -0.03912907  0.0036763   0.07563546 -0.02299793 -0.01903649 -0.05896062\n",
      "  0.06914204  0.03984906 -0.0356699   0.07500588  0.02960422 -0.06865672\n",
      " -0.06381108 -0.05951216]\n",
      "w4 = [ 0.00076752  0.07216509 -0.04682332  0.07209965  0.0732206  -0.02780577\n",
      " -0.03912907  0.0036763   0.07563546 -0.02299793 -0.01903649 -0.05896062\n",
      "  0.06914204  0.03984906 -0.0356699   0.07500588  0.02960422 -0.06865672\n",
      " -0.06381108 -0.05951216]\n",
      "w5 = [ 0.00076752  0.07216509 -0.04682332  0.07209965  0.0732206  -0.02780577\n",
      " -0.03912907  0.0036763   0.07563546 -0.02299793 -0.01903649 -0.05896062\n",
      "  0.06914204  0.03984906 -0.0356699   0.07500588  0.02960422 -0.06865672\n",
      " -0.06381108 -0.05951216]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters=initialize_weight()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"w1 = \" + str(parameters[\"w1\"].eval()[1,1,1]))\n",
    "    print(\"w2 = \" + str(parameters[\"w2\"].eval()[1,1,1]))\n",
    "    print(\"w3 = \" + str(parameters[\"w3\"].eval()[1,1,1]))\n",
    "    print(\"w4 = \" + str(parameters[\"w4\"].eval()[1,1,1]))\n",
    "    print(\"w5 = \" + str(parameters[\"w5\"].eval()[1,1,1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_prop(X,parameters):\n",
    "    \n",
    "        \n",
    "\n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    w1 = parameters['w1']\n",
    "    w2 = parameters['w2']\n",
    "    w3 = parameters['w3']\n",
    "    w4 = parameters['w4']\n",
    "    w5 = parameters['w5']\n",
    "    \n",
    "    ### START CODE HERE ###     \n",
    "    #CONV2D: stride of 1\n",
    "    z1=tf.nn.conv2d(X,w1,strides=[1,1,1,1],padding=\"VALID\")\n",
    "    #Relu\n",
    "    a1=tf.nn.relu(z1)\n",
    "    # MAXPOOL: window 2x2, stride 2\n",
    "    p1=tf.nn.max_pool(a1,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    # CONV2D: filters w2, stride 1\n",
    "    z2=tf.nn.conv2d(p1,w2,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    #Relu\n",
    "    a2=tf.nn.relu(z2)\n",
    "    #MAXPOOL: window 2x2, stride 2 \n",
    "    p2=tf.nn.max_pool(a2,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    # CONV2D: filters W3, stride 1\n",
    "    z3=tf.nn.conv2d(p2,w3,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    #Relu\n",
    "    a3=tf.nn.relu(z3)\n",
    "    #MAXPOOL: window 2x2, stride 2\n",
    "    p3=tf.nn.max_pool(a3,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    # CONV2D: filters W4, stride 1\n",
    "    z4=tf.nn.conv2d(p3,w4,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    #Relu\n",
    "    a4=tf.nn.relu(z4)\n",
    "    #MAXPOOL: window 2x2, stride 2 \n",
    "    p4=tf.nn.max_pool(a4,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    # CONV2D: filters W5, stride 1\n",
    "    z5=tf.nn.conv2d(p4,w5,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    #Relu\n",
    "    a5=tf.nn.relu(z5)\n",
    "    #MAXPOOL: window 2x2, stride 2 \n",
    "    p5=tf.nn.max_pool(a5,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    # FLATTEN\n",
    "    p5 = tf.contrib.layers.flatten(p5)\n",
    "    # FULLY-CONNECTED Layer 1\n",
    "    fc1 = tf.contrib.layers.fully_connected(p5, 100, activation_fn=tf.nn.relu)\n",
    "    # FULLY-CONNECTED Layer 2\n",
    "    fc2 = tf.contrib.layers.fully_connected(fc1,100,activation_fn=tf.nn.relu)\n",
    "    # FULLY-CONNECTED Hash layer creating 48 bit binary hash code\n",
    "    hashlayer=tf.contrib.layers.fully_connected(fc2,48,activation_fn=tf.nn.sigmoid)\n",
    "    bn=tf.divide(tf.add(tf.sign(tf.subtract(hashlayer,0.5)),1),2)\n",
    "    ### END CODE HERE ###\n",
    "    #print (type(bn))\n",
    "    return bn,fc2\n",
    "\n",
    "    \n",
    "   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = [[ 1.  1.  1.  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.\n",
      "   1.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  1.  0.  0.  1.\n",
      "   1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.\n",
      "   1.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  1.  0.  0.  1.\n",
      "   1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.\n",
      "   1.  1.  0.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  1.  0.  0.  1.\n",
      "   1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.]\n",
      " [ 1.  1.  1.  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.\n",
      "   1.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  0.  1.\n",
      "   1.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholder(32, 32, 3, 100)\n",
    "    parameters = initialize_weight()\n",
    "    h,z3 = forward_prop(X, parameters)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(h, {X: np.random.randn(4,32,32,3), Y: np.random.randn(4,100)})\n",
    "    print(\"h = \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"fully_connected_1/Relu:0\", shape=(?, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print (z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(z3, Y):\n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax(logits=z3, name=None))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.01\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    np.random.seed(1)\n",
    "    X, Y = create_placeholder(32, 32, 3, 100)\n",
    "    parameters = initialize_weight()\n",
    "    h,z3 = forward_prop(X, parameters)\n",
    "    cost = compute_cost(z3, Y)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    a = sess.run(cost, {X: np.random.randn(1,32,32,3), Y: np.random.randn(1,100)})\n",
    "    print(\"cost = \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hash_input=[]\n",
    "batchsize=10000\n",
    "num_epochs=1\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,print_cost = True):\n",
    "        \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_h, n_w, n_c) = X_train.shape             \n",
    "    label = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    X, Y = create_placeholder(n_h, n_w, n_c, label)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_weight()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    h,z3 = forward_prop(X, parameters)\n",
    "    hash_input.append(h)\n",
    "\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / batchsize) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            for index, offset in enumerate(range(0, len(X_train), batchsize)):\n",
    "                batch_x, batch_y = X_train[offset: offset + batchsize], Y_train[offset: offset + batchsize]\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: batch_x, Y: batch_y})\n",
    "            \n",
    "            minibatch_cost += temp_cost / num_minibatches\n",
    "         # Print the cost every epoch\n",
    "        if print_cost == True and epoch % 5 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "        if print_cost == True and epoch % 1 == 0:\n",
    "            costs.append(minibatch_cost)\n",
    "            \n",
    "       # plot the cost\n",
    "        #plt.plot(np.squeeze(costs))\n",
    "        #plt.ylabel('cost')\n",
    "        #plt.xlabel('iterations (per tens)')\n",
    "        #plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        #plt.show()\n",
    "        \n",
    "        #Calculate the correct predictions\n",
    "        predict_op = tf.argmax(z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        \n",
    "        return parameters,hash_input\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters,hash_input=model(X_train, y_train, X_test, y_test,0.09,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hash_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
